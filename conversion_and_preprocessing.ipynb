{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "831d3779-2e13-46e1-ad1c-0ce63a7005a6",
   "metadata": {},
   "source": [
    "# Omzetten van conllu naar txt, en weer terug.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82348e3a-58e7-40ea-ae9c-88fa528f98e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert conll to txt:\n",
    "\n",
    "conllfile = 'en_ewt-up-dev.conllu'\n",
    "outputfile = conllfile.replace('.conllu', '.txt')\n",
    "\n",
    "open_conll_file = open(conllfile, 'r', encoding='utf-8')\n",
    "\n",
    "for element in convert_file:\n",
    "    lines = convert_file.readlines()\n",
    "    #print(lines)\n",
    "\n",
    "conll_to_text = open(outputfile, 'w', encoding='utf-8')\n",
    "\n",
    "for element in lines:\n",
    "    conll_to_text.write(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07704b68-89b3-4988-a943-0a80d3101618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: remove # elements and empty lines. Stores it into a new txt file.\n",
    "\n",
    "with open('en_ewt-up-dev.txt', 'r', encoding='utf-8') as f:\n",
    "    lines=f.readlines()\n",
    "\n",
    "data_list = []\n",
    "for row in lines:\n",
    "    if row.startswith('#'):\n",
    "        continue\n",
    "\n",
    "    elif row.startswith('\\n'):\n",
    "        continue\n",
    "\n",
    "    else:\n",
    "        data_list.append(row)\n",
    "    \n",
    "#print(data_list[:10])\n",
    "\n",
    "textfile_new = open('new_file.conll', 'w', encoding='utf-8')\n",
    "for element in data_list:\n",
    "    textfile_new.write(element)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94486e71-fc65-4724-b2fd-19548baa3d75",
   "metadata": {},
   "source": [
    "# Probeersels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8752bac7-54bd-4f2c-b585-617904f907cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from conllu import parse\n",
    "\n",
    "sentences = parse(open('en_ewt-up-dev.conllu', 'r', encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd2225ea-1e3a-49af-94c8-043b42e58263",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install conllu==3.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b7faa09-d6cf-42da-9380-c5b03d64a397",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb692e06-f30e-4c33-bc23-1050ae939a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TokenList<From, the, AP, comes, this, story, :>\n"
     ]
    }
   ],
   "source": [
    "sentence = sentences[0]\n",
    "\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89aa43df-03a8-4586-9970-ddba63b5a6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From\n"
     ]
    }
   ],
   "source": [
    "token= sentence[0]\n",
    "\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ec7e994-88be-4b50-b9c2-7675766beb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import open\n",
    "from conllu import parse_incr\n",
    "\n",
    "\n",
    "new_list = []\n",
    "data_file = open(\"en_ewt-up-dev.conllu\", \"r\", encoding=\"utf-8\")\n",
    "for tokenlist in parse_incr(data_file):\n",
    "    #print(tokenlist)\n",
    "    new_list.append(tokenlist)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef3cbf85-bbf0-461c-9653-8aa274e03a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From\n"
     ]
    }
   ],
   "source": [
    "sentence = new_list[0]\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26cbaaff-541b-471e-9fc7-34a25572d474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From\n"
     ]
    }
   ],
   "source": [
    "token = sentence[0]\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03fda01e-635b-4ad6-ad98-743093b192ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['# newdoc id = weblog-blogspot.com_nominations_20041117172713_ENG_20041117_172713', '# sent_id = weblog-blogspot.com_nominations_20041117172713_ENG_20041117_172713-0001', '# text = From the AP comes this story :', '# sent_id = weblog-blogspot.com_nominations_20041117172713_ENG_20041117_172713-0002', '# text = President Bush on Tuesday nominated two individuals to replace retiring jurists on federal courts in the Washington area.', '# sent_id = weblog-blogspot.com_nominations_20041117172713_ENG_20041117_172713-0003', '# text = Bush nominated Jennifer M. Anderson for a 15-year term as associate judge of the Superior Court of the District of Columbia, replacing Steffen W. Graae.', '# sent_id = weblog-blogspot.com_nominations_20041117172713_ENG_20041117_172713-0004', '# text = ***', '# sent_id = weblog-blogspot.com_nominations_20041117172713_ENG_20041117_172713-0005']\n",
      "[['# newdoc id = weblog-blogspot.com_nominations_20041117172713_ENG_20041117_172713'], ['# sent_id = weblog-blogspot.com_nominations_20041117172713_ENG_20041117_172713-0001'], ['# text = From the AP comes this story :'], ['1', 'From', 'from', 'ADP', 'IN', '_', '3', 'case', '3:case', '_', '_', '_'], ['2', 'the', 'the', 'DET', 'DT', 'Definite=Def|PronType=Art', '3', 'det', '3:det', '_', '_', '_'], ['3', 'AP', 'AP', 'PROPN', 'NNP', 'Number=Sing', '4', 'obl', '4:obl:from', '_', '_', 'ARG2'], ['4', 'comes', 'come', 'VERB', 'VBZ', 'Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin', '0', 'root', '0:root', '_', 'come.03', 'V'], ['5', 'this', 'this', 'DET', 'DT', 'Number=Sing|PronType=Dem', '6', 'det', '6:det', '_', '_', '_'], ['6', 'story', 'story', 'NOUN', 'NN', 'Number=Sing', '4', 'nsubj', '4:nsubj', '_', '_', 'ARG1'], ['7', ':', ':', 'PUNCT', ':', '_', '4', 'punct', '4:punct', '_', '_', '_']]\n",
      "[['# newdoc id = weblog-blogspot.com_nominations_20041117172713_ENG_20041117_172713'], ['# sent_id = weblog-blogspot.com_nominations_20041117172713_ENG_20041117_172713-0001'], ['# text = From the AP comes this story :'], ['1', 'From', 'from', 'ADP', 'IN', '_', '3', 'case', '3:case', '_', '_', '_'], ['2', 'the', 'the', 'DET', 'DT', 'Definite=Def|PronType=Art', '3', 'det', '3:det', '_', '_', '_'], ['3', 'AP', 'AP', 'PROPN', 'NNP', 'Number=Sing', '4', 'obl', '4:obl:from', '_', '_', 'ARG2'], ['4', 'comes', 'come', 'VERB', 'VBZ', 'Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin', '0', 'root', '0:root', '_', 'come.03', 'V'], ['5', 'this', 'this', 'DET', 'DT', 'Number=Sing|PronType=Dem', '6', 'det', '6:det', '_', '_', '_'], ['6', 'story', 'story', 'NOUN', 'NN', 'Number=Sing', '4', 'nsubj', '4:nsubj', '_', '_', 'ARG1'], ['7', ':', ':', 'PUNCT', ':', '_', '4', 'punct', '4:punct', '_', '_', '_']]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "conllfile = 'en_ewt-up-dev.conllu'\n",
    "conllinput = open(conllfile, 'r', encoding = 'utf-8')\n",
    "    #delimiter indicates we are working with a tab separated value (default is comma)\n",
    "    #quotechar has as default value '\"', which is used to indicate the borders of a cell containing longer pieces of text\n",
    "    #in this file, we have only one token as text, but this token can be '\"', which then messes up the format. We set quotechar to a character that does not occur in our file\n",
    "csvreader = csv.reader(conllinput, delimiter='\\t',quotechar='|')\n",
    "\n",
    "not_important = []\n",
    "for row in csvreader:\n",
    "    for line in row:\n",
    "        #print(line)\n",
    "        if line.startswith('#'):\n",
    "            not_important.append(line)\n",
    "        else:\n",
    "            continue\n",
    "print(not_important[:10])\n",
    "\n",
    "conllinput = open(conllfile, 'r', encoding = 'utf-8')\n",
    "csvreader = csv.reader(conllinput, delimiter='\\t',quotechar='|')\n",
    "\n",
    "important = []\n",
    "for joe in csvreader:\n",
    "    if joe == '\\n':\n",
    "        continue\n",
    "    else:\n",
    "        important.append(joe)\n",
    "        \n",
    "print(important[:10])\n",
    "\n",
    "\n",
    "res = [i for i in important if i not in not_important]\n",
    "print(res[:10])\n",
    "\n",
    "\n",
    "# df = pd.DataFrame(new_list)\n",
    "\n",
    "# df\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
